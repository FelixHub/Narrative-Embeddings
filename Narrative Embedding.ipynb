{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrative Embeddings for clinical report classification\n",
    "\n",
    "Ok, so we have a database of clinical incident report, in the form of chronologic stories narrated by one of the healthcare professionnal concerned.\n",
    "\n",
    "There's a lot of research papers trying to analyze narratives as chronological orderered series of events, with various actors. Using those tools might help greatly to classify our clinical report, every available words or documents vector embeddings are indeed lacking of any narrative representation. I am trying to create a 'narrative embedding' for my reports, that i will use to train and test multi-label classification model. \n",
    "\n",
    "This is a three steps project : \n",
    "\n",
    "1) Extracting event chains from my dataset according to the 2009 paper of Chambers https://www.usna.edu/Users/cs/nchamber/pubs/acl09-narrative-schema.pdf\n",
    "\n",
    "2) Create Narrative Event Evolutionnary Graph (NEEG) according to the paper arXiv:1805.05081v2 \n",
    "\n",
    "3) Implement a Scaled Graph neural network, i.e neural network that will take NEEG in input.\n",
    "\n",
    "I use Spacy and the HuggingFace coreference parser to extract event chains from the database : https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1fc89d4e9c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[It: [It, It], us: [us, we, our, us, our, we, We], the long day: [the long day, the day, the day], the approach: [the approach, the approach], the runway: [the runway, the runway, the parallel runway], the ILS: [the ILS, It, it], the Controller: [the Controller, the Controller]]\n",
      "It was a late flight and both of us were getting tired from the long day. It was leg three plus I had commuted by air to start the day. The total flight was 3 hours. Everything went great until we were cleared for the approach. It was hazy with a visibility of 5 miles. I was looking for the runway but because our windows were fogged up more than usual I could not see very well. As I armed the approach I did not realize I had the VOR, not the ILS tuned as the active frequency. It was in the backup. As I looked at the FMA, I noticed it had VAPP instead of LOC. I finally saw the runway while still on the initial heading the Controller had given to us and by that time--as I tried to turn--the Controller cancelled our approach clearance and we were vectored back around. Because the LOC was not tuned, nothing was ever captured. It was very late and both the Captain and I were very tired from the day. We should have been more vigilant, checked and cross checked everything more than usual. Someone could have been landing on the parallel runway and that would have been an even bigger issueLearn to check everything 10x more when you are very tired with late flights. You may catch something new each time you cross check. Be sure the correct frequencies are in the right position to be armed.\n"
     ]
    }
   ],
   "source": [
    "# first try on ASRS database\n",
    "df = pd.read_excel('datasets/ASRStotal.xlsx')\n",
    "df.dropna(how='all', axis=1)\n",
    "\n",
    "doc = nlp(df.Narrative[30001])\n",
    "print(doc._.coref_clusters)\n",
    "print(df.Narrative[30001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(str(doc._.coref_resolved))\n",
    "\n",
    "events = []\n",
    "\n",
    "for token in doc2 :\n",
    "    event = { 'predicat': '', 'subj':'','obj':'','iobj':''}\n",
    "    if token.pos_ == \"VERB\" : \n",
    "        event['predicat'] = token\n",
    "        for t in token.children :\n",
    "            if t.dep_ == \"nsubj\" or t.dep_ == \"nsubjpass\" :\n",
    "                #print(\" \".join([t2.text for t2 in t.subtree]))\n",
    "                event['subj'] = t.subtree\n",
    "            if (t.dep_ == \"dobj\" or t.dep_ == \"obj\" or t.dep_ == \"pobj\") :\n",
    "                #print(token,\" \".join([t2.text for t2 in t.subtree]))\n",
    "                event['obj'] = t.subtree\n",
    "            if t.dep_ == \"prep\" :\n",
    "                #print(\" \".join([t2.text for t2 in t.subtree]))\n",
    "                event['iobj'] = t.subtree\n",
    "        events.append(event)\n",
    "        \n",
    "print(len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
